{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (1,2,5,6,7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "twitter1 = pd.read_csv(\"./data/twitter1_output.csv\", encoding='utf-8')\n",
    "twitter2 = pd.read_csv(\"./data/twitter2_output.csv\", encoding='utf-8')\n",
    "reddit = pd.read_csv(\"./data/reddit_clean_output.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def filterSubReddits(temp):\n",
    "    subreddit_omit = ['formula', 'F1', \"nascar\", \"AmericanHorrorStory\"]\n",
    "\n",
    "    for sub in subreddit_omit:\n",
    "        temp = temp[~temp['subreddit'].str.lower().str.contains(sub, na = False)]\n",
    "        \n",
    "    return temp\n",
    "\n",
    "def getRedditData(data, min_date, rolling_window):\n",
    "    \n",
    "    #   convert date str\n",
    "    #     target_date = \"2015-01-01\"\n",
    "    data['created'] = pd.to_datetime(data['created'], format='%Y/%m/%d',errors='coerce') \n",
    "    temp = data[data['created'] > min_date]\n",
    "    \n",
    "    temp = filterSubReddits(temp)\n",
    "    \n",
    "    for row in temp.itertuples():\n",
    "        temp.loc[row.Index, 'created'] = row.created.date()\n",
    "#         temp.loc[row.Index, 'sentiment'] = getSentiment(row.body)\n",
    "\n",
    "    #group by date and sentiment and unstack\n",
    "    df = temp.groupby(['created','0']).size().unstack(level=-1).fillna(0)\n",
    "    #fill in missing time series with 0 values\n",
    "    df = df.resample('D').mean().fillna(0)\n",
    "    #generate rolling window, sort reverse\n",
    "    df = df.rolling(rolling_window).sum()[::-1]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getTwitter(data, min_date, rolling_window):\n",
    "    \n",
    "    #   convert date str\n",
    "    #     target_date = \"2015-01-01\"\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%Y/%m/%d',errors='coerce') \n",
    "    temp = data[data['date'] > min_date]\n",
    "        \n",
    "    for row in temp.itertuples():\n",
    "        temp.loc[row.Index, 'date'] = row.date.date()\n",
    "#         temp.loc[row.Index, 'sentiment'] = getSentiment(row.body)\n",
    "\n",
    "    #group by date and sentiment and unstack\n",
    "    df = temp.groupby(['date','0']).size().unstack(level=-1).fillna(0)\n",
    "    #fill in missing time series with 0 values\n",
    "    df = df.resample('D').mean().fillna(0)\n",
    "    #generate rolling window, sort reverse\n",
    "    df = df.rolling(rolling_window).sum()[::-1]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter = twitter2.append(twitter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "tweetSen1 = getTwitter(twitter, '2019-05-01', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetSen1.to_csv(\"tweetSen1.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditSen = getRedditData(reddit, '2015-01-05', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditSen\n",
    "redditSen.to_csv(\"final_sentiments.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetSen1.join(tweetSen2, lsuffix='date', rsuffix='date')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
